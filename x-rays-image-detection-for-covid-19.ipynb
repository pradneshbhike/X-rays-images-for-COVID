{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font size=\"+3\" color=black ><b> <center><u>X-ray Image Detection for covid-19 Using CNN</u></center></b></font><br><a id=\"top\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>Table of Content</b></font>"},{"metadata":{},"cell_type":"markdown","source":"1. Importing Library\n2. Reading Datasets\n3. Normal Image\n4. Covid Images\n5. Train the Model\n6. Model Summary\n6. Plotting the Graph\n7. Accuracy\n8. Labeling and Prediction\n9. Confusion Matrix"},{"metadata":{},"cell_type":"markdown","source":"# <font color='blue'> Importing the Library </font>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport plotly.offline as py\nimport plotly.express as px\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color='blue'> Reading Dataset </font>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = '/kaggle/input/covid-19-x-ray-10000-images/dataset'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Normal Image </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_images = []\nfor img_path in glob.glob(data + '/normal/*'):\n    normal_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('Normal Image')\nplt.imshow(normal_images[0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Covid Image</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_images = []\nfor img_path in glob.glob(data + '/covid/*'):\n    covid_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('covid Image')\nplt.imshow(covid_images[0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Input Shape, Epochs and Batch Size\n\n    - Epochs - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\n    - Batch Size -Total number of training examples present in a single batch."},{"metadata":{"trusted":true},"cell_type":"code","source":"Image_Width = 150\nImage_Height = 150\nCannels = 3\n\nINPUT_SHAPE = (Image_Width, Image_Height, Cannels)\nNB_CLASSES = 2\nEPOCHS = 40\nBATCH_SIZE = 6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Train the model </font>\n\n\nKeras offers two different ways of defining a network. We will the Sequential API, where you just add on one layer at a time, starting from the input.\n\nThe most important part are the convolutional layers Conv2D. Here they have 16-32 filters that use nine weights each to transform a pixel to a weighted average of itself and its eight neighbors. As the same nine weights are used over the whole image, the net will pick up features that are useful everywhere. As it is only nine weights, we can stack many convolutional layers on top of each other without running out of memory/time.\n\nThe MaxPooling layers just look at four neighboring pixels and picks the maximal value. This reduces the size of the image by half, and by combining convolutional and pooling layers, the net be able to combine its features to learn more global features of the image. In the end we use the features in two fully-connected (Dense) layers.\n\nBatch Normalization is a technical trick to make training faster. Dropout is a regularization method, where the layer randomly replaces a proportion of its weights to zero for each training sample. This forces the net to learn features in a distributed way, not relying to much on a particular weight, and therefore improves generalization. 'relu' is the activation function x -> max(x,0).\n\nApplying Convolutional Neural Network which is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. Convolution is a mathematical operation to merge two sets of information.In CNN architectures, pooling is typically performed with 2x2 windows, stride 2 and no padding. While convolution is done with 3x3 windows, stride 1 and with padding\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model needs to be compiled before training can start. As our loss function, we use logloss which is called \"binary_crossentropy\" in Keras. Metrics is only used for evaluation. As optimizer, we could have used rmsprop, but Adam is faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Model Summary </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model1.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another important method to improve generalization is augmentation. This means generating more training data by randomly perturbing the images. If done in the right way, it can force the net to only learn translation-invariant features. If you train this model over hundreds of epochs, augmentation will definitely improve your performance. Here in the Kernel, we will only look at each image 4-5 times, so the difference is smaller. We use a Keras function for augmentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.25)\n\ntrain_generator = train_datagen.flow_from_directory(\n    data,\n    target_size=(Image_Height, Image_Width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    data, \n    target_size=(Image_Height, Image_Width),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples // BATCH_SIZE,\n    epochs = EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Plotting Graph - Accuracy and Loss</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,2, figsize=(14,5))\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'test'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Accuracy </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training_accuracy\", history.history['accuracy'][-1])\nprint(\"validation_accuracy\", history.history['val_accuracy'][-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Labeling & Prediction </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"label = validation_generator.classes\npred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'>Confusion Matrix </font>\nA confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (6,6))\nfrom sklearn.metrics import confusion_matrix\ncf = confusion_matrix(predicted_class_indices,label)\nsns.heatmap(cf,cmap= \"Blues\", linecolor = 'black' , annot = True, fmt='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = np.nonzero(predicted_class_indices == label)[0]\npred_class = predicted_class_indices.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(validation_generator[0][0][c].reshape(150,150,3))\n    plt.title(\"Predicted Class {},Actual Class {}\".format(pred_class.reshape(1,-1)[0][c], label[c]))\n    plt.tight_layout()\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### refrences\n### https://www.kaggle.com/madz2000/x-ray-detection-using-cnn-100-accuracy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}